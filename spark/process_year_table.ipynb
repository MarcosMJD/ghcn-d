{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c85f89ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import StructType, IntegerType, DateType, StructField, StringType, TimestampType\n",
    "import logging, traceback\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f4a07df",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL_PREFIX = 'https://noaa-ghcn-pds.s3.amazonaws.com'\n",
    "TEMP_STORAGE_PATH = '/home/marcos/ghcn-d/spark/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32fe94ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/marcos/bin/spark-3.2.1-bin-hadoop3.2/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/04/04 10:24:26 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('test') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bea1a591",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(url, local_file_path):\n",
    "    # NOTE the stream=True parameter below\n",
    "    with requests.get(url, stream=True) as r:\n",
    "        r.raise_for_status()\n",
    "        with open(local_file_path, 'wb') as f:\n",
    "            for chunk in r.iter_content(chunk_size=8192): \n",
    "                # If you have chunk encoded response uncomment if\n",
    "                # and set chunk_size parameter to None.\n",
    "                #if chunk: \n",
    "                f.write(chunk)\n",
    "    return local_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f54a4786",
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 1888\n",
    "csv_file_name = f'/{year}.csv'\n",
    "dataset_url = URL_PREFIX + '/csv' + csv_file_name\n",
    "csv_file_path = TEMP_STORAGE_PATH + csv_file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2925bc4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/marcos/ghcn-d/spark/data/1888.csv'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "download_file(dataset_url, csv_file_path)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4e8db7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stations = spark.read.parquet('./data/ghcnd-stations.parquet') \\\n",
    "  .drop('state', 'gsn_flag', 'hcn_crn_flag', 'wmo_id') \\\n",
    "  .withColumnRenamed('name', 'station_name') \\\n",
    "  .withColumnRenamed('id', 'station_id') \\\n",
    "  .withColumn('country_code', F.substring('station_id', 0, 2))\n",
    "\n",
    "df_countries = spark.read.parquet('./data/ghcnd-countries.parquet') \\\n",
    "  .withColumnRenamed('name', 'country_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "efa1081f",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"id\", StringType(), True),\n",
    "    StructField(\"date\", IntegerType(), True),\n",
    "    StructField(\"element\", StringType(), True),   \n",
    "    StructField(\"value\", IntegerType(), True),   \n",
    "    StructField(\"m_flag\", StringType(), True),   \n",
    "    StructField(\"q_flag\", StringType(), True),   \n",
    "    StructField(\"s_flag\", StringType(), True),\n",
    "    StructField(\"obs_time\",IntegerType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "985fd094",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read \\\n",
    "    .options(header=False) \\\n",
    "    .schema(schema) \\\n",
    "    .csv(csv_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "888b7714",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"date\", F.to_date(df.date.cast(\"string\"), \"yyyyMMdd\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a307c657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing year 1888...\n"
     ]
    }
   ],
   "source": [
    "print(f'processing year {year}...')\n",
    "  # Only used when reading from csv in order to convert to date. \n",
    "  # If reading from BQ, this is already done\n",
    "  # df = df.withColumn(\"date\", F.to_date(df.date.cast(\"string\"), \"yyyyMMdd\"))\n",
    "\n",
    "df = df \\\n",
    ".drop(\"q_flag\") \\\n",
    ".withColumn(\"tmax\", \n",
    "      F.when(df.element == \"TMAX\", \n",
    "          F.when(df.value > 700, None).otherwise(\n",
    "              F.when(df.value < -700, None). otherwise(\n",
    "                  df.value.cast(\"double\")/10)\n",
    "              )\n",
    "      ).otherwise(\"None\")\n",
    "  ) \\\n",
    "  .withColumn(\"tmin\", \n",
    "      F.when(df.element == \"TMIN\", \n",
    "          F.when(df.value > 700, None).otherwise(\n",
    "              F.when(df.value < -700, None). otherwise(\n",
    "                  df.value.cast(\"double\")/10)\n",
    "              )\n",
    "      ).otherwise(\"None\")\n",
    "  ) \\\n",
    "  .withColumn(\"prcp\", F.when(df.element == \"PRCP\", df.value.cast(\"double\")).otherwise(None)) \\\n",
    "  .withColumn(\"snow\", F.when(df.element == \"SNOW\", df.value.cast(\"double\")).otherwise(None)) \\\n",
    "  .withColumn(\"snwd\", F.when(df.element == \"SNWD\", df.value.cast(\"double\")).otherwise(None))\n",
    "\n",
    "df_daily = df \\\n",
    "    .withColumn(\"date\", F.trunc(\"date\", \"year\")) \\\n",
    "    .groupBy(\"id\", \"date\").agg( \n",
    "      F.avg(\"tmax\"),\n",
    "      F.avg(\"tmin\"),\n",
    "      F.avg(\"prcp\"),\n",
    "      F.avg(\"snow\"),\n",
    "      F.avg(\"snwd\"),\n",
    "      F.first(\"m_flag\"),\n",
    "      F.first(\"s_flag\")\n",
    "    ) \\\n",
    "    .join(df_stations, df.id == df_stations.station_id, \"inner\") \\\n",
    "    .join(df_countries, df_stations.country_code == df_countries.code, \"inner\") \\\n",
    "    .drop ('station_id', 'code') \\\n",
    "    .toDF('id','date','tmax','tmin','prcp','snow','snwd','m_flag','s_flag','latitude','longitude','elevation','station_name','country_code','country_name') \\\n",
    "\n",
    "   \n",
    "# Note: toDF after joins, otherwise join will raise error\n",
    "# Note: toDF since BQ does not allow field names with () and average generates these kind of names avg(tmax)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8320ff9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 37:===========================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+------------------+-------------------+------------------+----+----+------+------+--------+---------+---------+--------------------+------------+------------+\n",
      "|         id|      date|              tmax|               tmin|              prcp|snow|snwd|m_flag|s_flag|latitude|longitude|elevation|        station_name|country_code|country_name|\n",
      "+-----------+----------+------------------+-------------------+------------------+----+----+------+------+--------+---------+---------+--------------------+------------+------------+\n",
      "|AGE00135039|1888-01-01| 22.00986301369863| 13.602203856749313|12.603825136612022|null|null|  null|     E| 35.7297|     0.65|     50.0|ORAN-HOPITAL MILI...|          AG|     Algeria|\n",
      "|AGE00147705|1888-01-01|22.432417582417592| 14.934615384615386|22.713498622589533|null|null|  null|     E|   36.78|     3.07|     59.0|ALGIERS-VILLE/UNI...|          AG|     Algeria|\n",
      "|AGE00147708|1888-01-01|23.526315789473685| 11.220221606648199|19.390581717451525|null|null|  null|     E|   36.72|     4.05|    222.0|          TIZI OUZOU|          AG|     Algeria|\n",
      "|AGE00147709|1888-01-01|17.682967032967035|  9.729670329670329|24.244505494505493|null|null|  null|     E|   36.63|      4.2|    942.0|       FORT NATIONAL|          AG|     Algeria|\n",
      "|AGE00147711|1888-01-01|  20.3810888252149|  9.255681818181818|16.008474576271187|null|null|  null|     E| 36.3697|     6.62|    660.0|         CONSTANTINE|          AG|     Algeria|\n",
      "|AGE00147712|1888-01-01|24.909117647058824| 10.698826979472141|10.197058823529412|null|null|  null|     E|   36.17|     1.34|    112.0|ORLEANSVILLE (CHLEF)|          AG|     Algeria|\n",
      "|AGE00147713|1888-01-01| 20.32130681818182|  7.466101694915254|11.628895184135978|null|null|  null|     E|   36.18|      5.4|   1081.0|               SETIF|          AG|     Algeria|\n",
      "|AGE00147715|1888-01-01|23.887921348314606|  9.330113636363636| 8.955307262569832|null|null|  null|     E|   35.42|   8.1197|    863.0|             TEBESSA|          AG|     Algeria|\n",
      "|AGE00147716|1888-01-01| 21.71629213483146| 13.126404494382022| 16.40449438202247|null|null|  null|     E|    35.1|    -1.85|     83.0| NEMOURS (GHAZAOUET)|          AG|     Algeria|\n",
      "|AGE00147717|1888-01-01| 23.52892561983471|  7.746556473829201| 11.93939393939394|null|null|  null|     E|    35.2|     0.63|    476.0|      SIDI-BEL-ABBES|          AG|     Algeria|\n",
      "|AGE00147718|1888-01-01|27.733888888888885| 15.298333333333337|  4.69672131147541|null|null|  null|     E|   34.85|     5.72|    125.0|              BISKRA|          AG|     Algeria|\n",
      "|AGE00147719|1888-01-01|26.520114942528735|  9.306590257879655| 4.275862068965517|null|null|  null|     E| 33.7997|     2.89|    767.0|            LAGHOUAT|          AG|     Algeria|\n",
      "|AGE00147720|1888-01-01|21.938271604938272|  5.667289719626169| 6.561728395061729|null|null|  null|     E|   33.68|      1.0|   1320.0|GERYVILLE (EL-BAY...|          AG|     Algeria|\n",
      "|AJ000037735|1888-01-01|              null|               null|10.232026143790849|null|null|  null|     r| 40.7167|  46.4167|    311.0|               GANCA|          AJ|  Azerbaijan|\n",
      "|AJ000037850|1888-01-01|              null|               null|  8.07103825136612|null|null|  null|     I|    40.4|     49.8|     47.0|                BAKU|          AJ|  Azerbaijan|\n",
      "|AM000037789|1888-01-01|              null|-1.5262295081967212|12.472677595628415|null|null|  null|     r|    40.2|     44.5|   1113.0|             YEREVAN|          AM|     Armenia|\n",
      "|ASN00001005|1888-01-01|              null|               null|               0.0|null|null|  null|     a|-15.4644|    128.1|     20.0|        WYNDHAM PORT|          AS|   Australia|\n",
      "|ASN00003007|1888-01-01|              null|               null|               0.0|null|null|  null|     a|-17.3044| 123.6292|      8.0|   DERBY POST OFFICE|          AS|   Australia|\n",
      "|ASN00003050|1888-01-01|              null|               null|               0.0|null|null|  null|     a|  -17.95| 124.1667|   -999.9|     LIVERINGA LOWER|          AS|   Australia|\n",
      "|ASN00004007|1888-01-01|              null|               null|               0.0|null|null|  null|     a|   -20.4| 118.4667|      6.0|            BOODARIE|          AS|   Australia|\n",
      "+-----------+----------+------------------+-------------------+------------------+----+----+------+------+--------+---------+---------+--------------------+------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_daily.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7c3879ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(id,StringType,true),StructField(date,DateType,true),StructField(tmax,DoubleType,true),StructField(tmin,DoubleType,true),StructField(prcp,DoubleType,true),StructField(snow,DoubleType,true),StructField(snwd,DoubleType,true),StructField(m_flag,StringType,true),StructField(s_flag,StringType,true),StructField(latitude,DoubleType,true),StructField(longitude,DoubleType,true),StructField(elevation,DoubleType,true),StructField(station_name,StringType,true),StructField(country_code,StringType,true),StructField(country_name,StringType,true)))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_daily.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981509c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
